{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import itertools\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "import sys\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class google_image_scrapper:\n",
    "    def __init__(self,num_images,output_dir):\n",
    "        self.REQUEST_HEADER = {'User-Agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"}\n",
    "        self.base_url=\"https://www.google.co.in/search?q={}&source=lnms&tbm=isch\"\n",
    "        self.num_images=num_images\n",
    "        self.output_dir=output_dir\n",
    "        self.timeout=2\n",
    "        \n",
    "    def get_soup(self,url):\n",
    "        response = urlopen(Request(url, headers=self.REQUEST_HEADER))\n",
    "        return BeautifulSoup(response, 'html.parser')\n",
    "    \n",
    "    def get_query_url(self,search_query):\n",
    "        return self.base_url.format(\"+\".join(search_query.split()))\n",
    "    \n",
    "    def extract_images_from_soup(self,soup):\n",
    "        image_elements = soup.find_all(\"div\", {\"class\": \"rg_meta\"})\n",
    "        metadata_dicts = (json.loads(e.text) for e in image_elements)\n",
    "        link_type_records = ((d[\"ou\"], d[\"ity\"]) for d in metadata_dicts)\n",
    "        return link_type_records\n",
    "    \n",
    "    def extract_images(self,query):\n",
    "        url = self.get_query_url(query)\n",
    "        print (\"Souping\")\n",
    "        soup = self.get_soup(url)\n",
    "        print (\"Extracting image urls\")\n",
    "        link_type_records = self.extract_images_from_soup(soup)\n",
    "        return itertools.islice(link_type_records, self.num_images+5)\n",
    "    \n",
    "    def get_raw_image(self,url):\n",
    "        req = Request(url, headers=REQUEST_HEADER)\n",
    "        try:\n",
    "            resp = urlopen(req,timeout=self.timeout)\n",
    "            resp=resp.read()\n",
    "        except timeout :\n",
    "            print (\"timeout occured\")\n",
    "            resp=None\n",
    "        except (HTTPError, URLError) as error:\n",
    "            print ('Data of %s not retrieved because %s\\nURL: %s', name, error, url)\n",
    "            resp=None\n",
    "        return resp\n",
    "    \n",
    "    def save_image(self,raw_image, image_type,image_number,dir_name):\n",
    "        extension = image_type if image_type else 'jpg'\n",
    "        save_path = os.path.join(self.output_dir, dir_name)\n",
    "        \n",
    "        if not os.path.exists(save_path):\n",
    "            print (\"creating directory {} \".format(save_path))\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        save_path = os.path.join(save_path, str(image_number))\n",
    "        with open(save_path, 'wb') as image_file:\n",
    "            image_file.write(raw_image)\n",
    "            \n",
    "    def download_images_to_dir(self,images,dir_name):\n",
    "        for i, (url, image_type) in enumerate(images):\n",
    "            try:\n",
    "                print (\"Making request ({}/{}): {}\".format(i+1, self.num_images, url))\n",
    "                raw_image = self.get_raw_image(url)\n",
    "                if (raw_image is None):\n",
    "                    continue\n",
    "                self.save_image(raw_image, image_type,i,dir_name)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "    \n",
    "    def run(self,query,dir_name):\n",
    "        print (\"Extracting image links\")\n",
    "        images = self.extract_images(query)\n",
    "        print(\"Downloading images\")\n",
    "        self.download_images_to_dir(images,dir_name)\n",
    "        print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_soup(url, header):\n",
    "#     response = urlopen(Request(url, headers=header))\n",
    "#     return BeautifulSoup(response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=google_image_scrapper(num_images=15, output_dir=\"./actors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting image links\n",
      "Souping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-10-31 11:13:43,745 DEBUG sjisprober]: SHIFT_JIS Japanese prober hit error at byte 314113\n",
      "[2018-10-31 11:13:44,646 DEBUG eucjpprober]: EUC-JP Japanese prober hit error at byte 314111\n",
      "[2018-10-31 11:13:45,204 DEBUG mbcharsetprober]: GB2312 Chinese prober hit error at byte 314113\n",
      "[2018-10-31 11:13:45,805 DEBUG mbcharsetprober]: EUC-KR Korean prober hit error at byte 314111\n",
      "[2018-10-31 11:13:46,391 DEBUG mbcharsetprober]: CP949 Korean prober hit error at byte 314111\n",
      "[2018-10-31 11:13:46,915 DEBUG mbcharsetprober]: Big5 Chinese prober hit error at byte 314112\n",
      "[2018-10-31 11:13:47,435 DEBUG mbcharsetprober]: EUC-TW Taiwan prober hit error at byte 314111\n",
      "[2018-10-31 11:13:49,526 DEBUG charsetgroupprober]: windows-1251 Russian confidence = 0.01\n",
      "[2018-10-31 11:13:49,527 DEBUG charsetgroupprober]: KOI8-R Russian confidence = 0.01\n",
      "[2018-10-31 11:13:49,527 DEBUG charsetgroupprober]: ISO-8859-5 Russian confidence = 0.0\n",
      "[2018-10-31 11:13:49,528 DEBUG charsetgroupprober]: MacCyrillic Russian confidence = 0.0\n",
      "[2018-10-31 11:13:49,533 DEBUG charsetgroupprober]: IBM866 Russian confidence = 0.0\n",
      "[2018-10-31 11:13:49,533 DEBUG charsetgroupprober]: IBM855 Russian confidence = 0.0\n",
      "[2018-10-31 11:13:49,534 DEBUG charsetgroupprober]: ISO-8859-7 Greek confidence = 0.0\n",
      "[2018-10-31 11:13:49,534 DEBUG charsetgroupprober]: windows-1253 Greek confidence = 0.0\n",
      "[2018-10-31 11:13:49,535 DEBUG charsetgroupprober]: ISO-8859-5 Bulgairan confidence = 0.0\n",
      "[2018-10-31 11:13:49,536 DEBUG charsetgroupprober]: windows-1251 Bulgarian confidence = 0.0\n",
      "[2018-10-31 11:13:49,536 DEBUG charsetgroupprober]: TIS-620 Thai confidence = 0.1719823420240646\n",
      "[2018-10-31 11:13:49,537 DEBUG charsetgroupprober]: ISO-8859-9 Turkish confidence = 0.33274879267406665\n",
      "[2018-10-31 11:13:49,537 DEBUG charsetgroupprober]: windows-1255 Hebrew confidence = 0.0\n",
      "[2018-10-31 11:13:49,538 DEBUG charsetgroupprober]: windows-1255 Hebrew confidence = 0.0\n",
      "[2018-10-31 11:13:49,538 DEBUG charsetgroupprober]: windows-1255 Hebrew confidence = 0.0\n",
      "[2018-10-31 11:13:49,539 DEBUG charsetgroupprober]: windows-1251 Russian confidence = 0.01\n",
      "[2018-10-31 11:13:49,539 DEBUG charsetgroupprober]: KOI8-R Russian confidence = 0.01\n",
      "[2018-10-31 11:13:49,540 DEBUG charsetgroupprober]: ISO-8859-5 Russian confidence = 0.0\n",
      "[2018-10-31 11:13:49,540 DEBUG charsetgroupprober]: MacCyrillic Russian confidence = 0.0\n",
      "[2018-10-31 11:13:49,541 DEBUG charsetgroupprober]: IBM866 Russian confidence = 0.0\n",
      "[2018-10-31 11:13:49,541 DEBUG charsetgroupprober]: IBM855 Russian confidence = 0.0\n",
      "[2018-10-31 11:13:49,542 DEBUG charsetgroupprober]: ISO-8859-7 Greek confidence = 0.0\n",
      "[2018-10-31 11:13:49,543 DEBUG charsetgroupprober]: windows-1253 Greek confidence = 0.0\n",
      "[2018-10-31 11:13:49,544 DEBUG charsetgroupprober]: ISO-8859-5 Bulgairan confidence = 0.0\n",
      "[2018-10-31 11:13:49,545 DEBUG charsetgroupprober]: windows-1251 Bulgarian confidence = 0.0\n",
      "[2018-10-31 11:13:49,546 DEBUG charsetgroupprober]: TIS-620 Thai confidence = 0.1719823420240646\n",
      "[2018-10-31 11:13:49,547 DEBUG charsetgroupprober]: ISO-8859-9 Turkish confidence = 0.33274879267406665\n",
      "[2018-10-31 11:13:49,548 DEBUG charsetgroupprober]: windows-1255 Hebrew confidence = 0.0\n",
      "[2018-10-31 11:13:49,549 DEBUG charsetgroupprober]: windows-1255 Hebrew confidence = 0.0\n",
      "[2018-10-31 11:13:49,549 DEBUG charsetgroupprober]: windows-1255 Hebrew confidence = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting image urls\n",
      "Downloading images\n",
      "Making request (0/15): http://www.pak101.com/gallery/ActorTv/Humayun_Saeed/2014/9/4/Humayun_Saeed_Pakistani_Male_Television_Actor_Celebrity_8_ltqlj_Pak101(dot)com.jpg\n",
      "creating directory ./actors/humayun_saeed/ \n",
      "Making request (1/15): https://i.ytimg.com/vi/DZ6tt-swXV8/maxresdefault.jpg\n",
      "name 'timeout' is not defined\n",
      "Making request (2/15): https://www.brandsynario.com/wp-content/uploads/humayun.png\n",
      "Making request (3/15): http://i.dawn.com/large/2015/11/56459323b08da.jpg\n",
      "Making request (4/15): http://www.fashionuniverse.net/wp-content/uploads/2016/09/14102407_647683002058089_6573988816502484003_n.jpg\n",
      "Making request (5/15): https://style.pk/wp-content/uploads/2012/06/Top-Actor-Humayun-Saeed-Full-Biography-0013.jpg\n",
      "Making request (6/15): http://www.pakshowbiz.com/wp-content/uploads/2017/01/Humayun-Saeed-Father.jpg\n",
      "Making request (7/15): https://cache.pakistantoday.com.pk/Humayun-Saeed-Ushna-Shah-Secret-Affair.jpg\n",
      "Making request (8/15): https://c.tribune.com.pk/2017/07/1457871-HumayunSaeed-1500024645-219-640x480.jpg\n",
      "name 'timeout' is not defined\n",
      "Making request (9/15): https://ww.web.pk/wp-content/uploads/2014/03/Humayun-Saeed-Ayesha-Khan-Scandal.jpg\n",
      "Making request (10/15): http://mwf.com.pk/images/stories/humayun%20saeed%20actor.jpg\n",
      "name 'timeout' is not defined\n",
      "Making request (11/15): https://www.sindhidunya.com/wp-content/uploads/2015/12/724598-humayncopy-1403278103-138-640x480.jpg\n",
      "Making request (12/15): https://3.bp.blogspot.com/-8UEGAYPC9cU/U4FiiRDwlKI/AAAAAAAACaY/kdgaeWpbnw4/s1600/Humayun+saeed+1.jpg\n",
      "Making request (13/15): https://i.ytimg.com/vi/Y1x4A3tpNPs/maxresdefault.jpg\n",
      "name 'timeout' is not defined\n",
      "Making request (14/15): https://dramaguru.net/images/actors/humayun_saeed_102.jpeg?w=315&h=350&fit=crop-top\n",
      "Making request (15/15): http://i.dawn.com/large/2015/12/56838dde112fb.jpg\n",
      "Making request (16/15): https://i2.wp.com/pakistanmediaupdates.com/wp-content/uploads/2014/03/humayun-saeed.jpg?resize=600%2C379\n",
      "Making request (17/15): https://www.brecorder.com/images/2015/09/jpna0.jpg\n",
      "Making request (18/15): http://i.hipinpakistan.com/large/2016/01/56864875e48e8.png\n",
      "name 'timeout' is not defined\n",
      "Making request (19/15): https://style.pk/wp-content/uploads/2012/06/Top-Actor-Humayun-Saeed-Full-Biography-004.jpg\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "a.run(\"actor humayun saeed\",\"humayun_saeed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./actor/jenni\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
